{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8241ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Missing Values Handling in CSV Datasets\n",
    "# Complete Jupyter Notebook with Functions, Examples, and Comparisons\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Missing Values Handler - Comprehensive Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: MISSING VALUES HANDLING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def drop_nulls(df):\n",
    "    \"\"\"\n",
    "    Remove all rows containing at least one null value.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with null rows removed\n",
    "        \n",
    "    Pros:\n",
    "        - Simple and straightforward\n",
    "        - Preserves data integrity for remaining records\n",
    "        - No assumptions about missing data\n",
    "        \n",
    "    Cons:\n",
    "        - Can significantly reduce dataset size\n",
    "        - May introduce bias if nulls are not random\n",
    "        - Loss of potentially valuable information\n",
    "    \"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "def replace_with_fixed(df, value=0):\n",
    "    \"\"\"\n",
    "    Replace all nulls with a user-defined value.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        value: Fixed value to replace nulls (default: 0)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with nulls replaced by fixed value\n",
    "        \n",
    "    Pros:\n",
    "        - Simple implementation\n",
    "        - Preserves dataset size\n",
    "        - Works with any data type\n",
    "        \n",
    "    Cons:\n",
    "        - May introduce artificial patterns\n",
    "        - Fixed value might not be meaningful\n",
    "        - Can skew statistical analysis\n",
    "    \"\"\"\n",
    "    return df.fillna(value)\n",
    "\n",
    "def replace_with_mean(df):\n",
    "    \"\"\"\n",
    "    Replace nulls in numeric columns with the column mean.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with numeric nulls replaced by mean\n",
    "        \n",
    "    Pros:\n",
    "        - Preserves column mean\n",
    "        - Reasonable for normally distributed data\n",
    "        - Maintains dataset size\n",
    "        \n",
    "    Cons:\n",
    "        - Reduces variance\n",
    "        - Not suitable for skewed distributions\n",
    "        - Only works with numeric data\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "    numeric_cols = df_filled.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df_filled[col].isnull().any():\n",
    "            mean_val = df_filled[col].mean()\n",
    "            df_filled[col].fillna(mean_val, inplace=True)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "def replace_with_median(df):\n",
    "    \"\"\"\n",
    "    Replace nulls in numeric columns with the column median.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with numeric nulls replaced by median\n",
    "        \n",
    "    Pros:\n",
    "        - Robust to outliers\n",
    "        - Good for skewed distributions\n",
    "        - Preserves central tendency\n",
    "        \n",
    "    Cons:\n",
    "        - May not preserve mean\n",
    "        - Reduces variance\n",
    "        - Only works with numeric data\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "    numeric_cols = df_filled.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df_filled[col].isnull().any():\n",
    "            median_val = df_filled[col].median()\n",
    "            df_filled[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "def replace_with_mode(df):\n",
    "    \"\"\"\n",
    "    Replace nulls with the most frequent value in each column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with nulls replaced by mode\n",
    "        \n",
    "    Pros:\n",
    "        - Works with categorical and numeric data\n",
    "        - Preserves most common patterns\n",
    "        - Logical for categorical variables\n",
    "        \n",
    "    Cons:\n",
    "        - May not exist for continuous variables\n",
    "        - Can introduce bias toward common values\n",
    "        - Multiple modes create ambiguity\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "    \n",
    "    for col in df_filled.columns:\n",
    "        if df_filled[col].isnull().any():\n",
    "            mode_val = df_filled[col].mode()\n",
    "            if not mode_val.empty:\n",
    "                df_filled[col].fillna(mode_val.iloc[0], inplace=True)\n",
    "            else:\n",
    "                # If no mode exists, use a default based on data type\n",
    "                if df_filled[col].dtype in ['object', 'category']:\n",
    "                    df_filled[col].fillna('Unknown', inplace=True)\n",
    "                else:\n",
    "                    df_filled[col].fillna(0, inplace=True)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "def forward_fill(df):\n",
    "    \"\"\"\n",
    "    Fill nulls with the previous non-null value (forward fill).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with forward-filled values\n",
    "        \n",
    "    Pros:\n",
    "        - Maintains temporal continuity\n",
    "        - Good for time series data\n",
    "        - Preserves trends\n",
    "        \n",
    "    Cons:\n",
    "        - Assumes values persist over time\n",
    "        - First rows may remain null\n",
    "        - May propagate outdated information\n",
    "    \"\"\"\n",
    "    return df.fillna(method='ffill')\n",
    "\n",
    "def backward_fill(df):\n",
    "    \"\"\"\n",
    "    Fill nulls with the next non-null value (backward fill).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with backward-filled values\n",
    "        \n",
    "    Pros:\n",
    "        - Good for time series preparation\n",
    "        - Fills early missing values\n",
    "        - Maintains data relationships\n",
    "        \n",
    "    Cons:\n",
    "        - Uses future information\n",
    "        - Last rows may remain null\n",
    "        - May not be logical for some contexts\n",
    "    \"\"\"\n",
    "    return df.fillna(method='bfill')\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: SAMPLE DATA CREATION\n",
    "# ============================================================================\n",
    "\n",
    "# Load sample dataset from CSV instead of creating synthetic data\n",
    "print(\"Loading sample dataset from 's.csv'...\")\n",
    "sample_df = pd.read_csv('sample_csv/sample.csv')\n",
    "\n",
    "print(\"Sample dataset loaded from 'sample_csv/sample.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: DATASET OVERVIEW AND ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Dataset shape: {sample_df.shape}\")\n",
    "print(f\"Total cells: {sample_df.size}\")\n",
    "print(f\"Missing values: {sample_df.isnull().sum().sum()}\")\n",
    "print(f\"Missing percentage: {(sample_df.isnull().sum().sum() / sample_df.size) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nMissing values by column:\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': sample_df.columns,\n",
    "    'Missing_Count': sample_df.isnull().sum().values,\n",
    "    'Missing_Percentage': (sample_df.isnull().sum().values / len(sample_df)) * 100,\n",
    "    'Data_Type': sample_df.dtypes.values\n",
    "})\n",
    "print(missing_summary)\n",
    "\n",
    "print(\"\\nFirst 10 rows of sample data:\")\n",
    "print(sample_df.head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: APPLYING MISSING VALUE HANDLING METHODS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"APPLYING MISSING VALUE HANDLING METHODS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "methods = {\n",
    "    'Original': sample_df,\n",
    "    'Drop Nulls': drop_nulls(sample_df),\n",
    "    'Fixed Value (0)': replace_with_fixed(sample_df, 0),\n",
    "    'Fixed Value (Unknown)': replace_with_fixed(sample_df, 'Unknown'),\n",
    "    'Mean Fill': replace_with_mean(sample_df),\n",
    "    'Median Fill': replace_with_median(sample_df),\n",
    "    'Mode Fill': replace_with_mode(sample_df),\n",
    "    'Forward Fill': forward_fill(sample_df),\n",
    "    'Backward Fill': backward_fill(sample_df)\n",
    "}\n",
    "\n",
    "# Apply each method and collect statistics\n",
    "for method_name, df_result in methods.items():\n",
    "    total_nulls = df_result.isnull().sum().sum()\n",
    "    shape = df_result.shape\n",
    "    results[method_name] = {\n",
    "        'dataframe': df_result,\n",
    "        'total_nulls': total_nulls,\n",
    "        'shape': shape,\n",
    "        'null_percentage': (total_nulls / df_result.size) * 100 if df_result.size > 0 else 0\n",
    "    }\n",
    "\n",
    "# Display results for each method\n",
    "for method_name, result in results.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Shape: {result['shape']}\")\n",
    "    print(f\"  Total nulls: {result['total_nulls']}\")\n",
    "    print(f\"  Null percentage: {result['null_percentage']:.2f}%\")\n",
    "    \n",
    "    if method_name != 'Original':\n",
    "        print(\"  First 5 rows:\")\n",
    "        print(result['dataframe'].head().to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: DETAILED COMPARISON AND VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DETAILED COMPARISON AND VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': list(results.keys()),\n",
    "    'Rows': [results[method]['shape'][0] for method in results.keys()],\n",
    "    'Columns': [results[method]['shape'][1] for method in results.keys()],\n",
    "    'Total_Nulls': [results[method]['total_nulls'] for method in results.keys()],\n",
    "    'Null_Percentage': [results[method]['null_percentage'] for method in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Comparison Summary:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Bar chart of remaining nulls\n",
    "axes[0, 0].bar(comparison_df['Method'], comparison_df['Total_Nulls'], color='skyblue')\n",
    "axes[0, 0].set_title('Total Null Values by Method')\n",
    "axes[0, 0].set_xlabel('Method')\n",
    "axes[0, 0].set_ylabel('Number of Nulls')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Bar chart of dataset sizes\n",
    "axes[0, 1].bar(comparison_df['Method'], comparison_df['Rows'], color='lightcoral')\n",
    "axes[0, 1].set_title('Dataset Size (Rows) by Method')\n",
    "axes[0, 1].set_xlabel('Method')\n",
    "axes[0, 1].set_ylabel('Number of Rows')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Null percentage\n",
    "axes[1, 0].bar(comparison_df['Method'], comparison_df['Null_Percentage'], color='lightgreen')\n",
    "axes[1, 0].set_title('Null Percentage by Method')\n",
    "axes[1, 0].set_xlabel('Method')\n",
    "axes[1, 0].set_ylabel('Null Percentage (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Heatmap of nulls by column for original data\n",
    "null_by_column = sample_df.isnull().sum()\n",
    "axes[1, 1].bar(range(len(null_by_column)), null_by_column.values, color='orange')\n",
    "axes[1, 1].set_title('Null Values by Column (Original Data)')\n",
    "axes[1, 1].set_xlabel('Column Index')\n",
    "axes[1, 1].set_ylabel('Number of Nulls')\n",
    "axes[1, 1].set_xticks(range(len(null_by_column)))\n",
    "axes[1, 1].set_xticklabels([col[:8] + '...' if len(col) > 8 else col \n",
    "                           for col in null_by_column.index], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: EDGE CASE DEMONSTRATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EDGE CASE DEMONSTRATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Edge Case 1: All nulls column\n",
    "print(\"Edge Case 1: Column with all null values\")\n",
    "print(\"Original 'all_nulls' column unique values:\", sample_df['all_null_column'].unique())\n",
    "\n",
    "print(\"\\nAfter mode fill:\")\n",
    "mode_filled = replace_with_mode(sample_df)\n",
    "print(\"Mode-filled 'all_nulls' column unique values:\", mode_filled['all_null_column'].unique())\n",
    "\n",
    "print(\"\\nAfter mean fill:\")\n",
    "mean_filled = replace_with_mean(sample_df)\n",
    "print(\"Mean-filled 'all_nulls' column (still null):\", mean_filled['all_null_column'].isnull().all())\n",
    "\n",
    "# Edge Case 2: Mixed-type column\n",
    "print(\"\\nEdge Case 2: Mixed-type column handling\")\n",
    "print(\"Original 'mixed_type' column sample values:\")\n",
    "print(sample_df['mixed_type'].dropna().head(10).tolist())\n",
    "\n",
    "print(\"\\nAfter mode fill (mixed-type):\")\n",
    "print(\"Mode-filled 'mixed_type' column sample values:\")\n",
    "print(mode_filled['mixed_type'].head(10).tolist())\n",
    "\n",
    "\n",
    "# Edge Case 3: Small dataset edge case\n",
    "print(\"\\nEdge Case 4: Very small dataset\")\n",
    "tiny_df = pd.DataFrame({\n",
    "    'A': [1, np.nan, 3],\n",
    "    'B': [np.nan, 5, np.nan],\n",
    "    'C': ['x', np.nan, 'z']\n",
    "})\n",
    "print(\"Tiny dataset:\")\n",
    "print(tiny_df)\n",
    "\n",
    "print(\"\\nAfter dropping nulls (tiny dataset):\")\n",
    "tiny_dropped = drop_nulls(tiny_df)\n",
    "print(tiny_dropped)\n",
    "print(f\"Remaining rows: {len(tiny_dropped)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: PERFORMANCE AND MEMORY CONSIDERATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE AND MEMORY CONSIDERATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def measure_performance(func, df, *args):\n",
    "    \"\"\"Measure execution time and memory usage of a function.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = func(df, *args)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    mem_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    return {\n",
    "        'execution_time': end_time - start_time,\n",
    "        'memory_delta': mem_after - mem_before,\n",
    "        'result_shape': result.shape\n",
    "    }\n",
    "\n",
    "# Create a larger dataset for performance testing\n",
    "print(\"Creating larger dataset for performance testing...\")\n",
    "large_df = sample_df\n",
    "# Replicate to make it larger\n",
    "large_df = pd.concat([large_df] * 10, ignore_index=True)\n",
    "\n",
    "print(f\"Large dataset shape: {large_df.shape}\")\n",
    "\n",
    "# Test performance of each method\n",
    "performance_results = {}\n",
    "methods_to_test = {\n",
    "    'drop_nulls': drop_nulls,\n",
    "    'replace_with_fixed': lambda df: replace_with_fixed(df, 0),\n",
    "    'replace_with_mean': replace_with_mean,\n",
    "    'replace_with_median': replace_with_median,\n",
    "    'replace_with_mode': replace_with_mode,\n",
    "    'forward_fill': forward_fill,\n",
    "    'backward_fill': backward_fill\n",
    "}\n",
    "\n",
    "for method_name, method_func in methods_to_test.items():\n",
    "    perf = measure_performance(method_func, large_df)\n",
    "    performance_results[method_name] = perf\n",
    "    print(f\"{method_name:20} | Time: {perf['execution_time']:.4f}s | \"\n",
    "          f\"Memory: {perf['memory_delta']:+.2f}MB | \"\n",
    "          f\"Result shape: {perf['result_shape']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 8: RECOMMENDATIONS AND BEST PRACTICES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECOMMENDATIONS AND BEST PRACTICES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "recommendations = \"\"\"\n",
    "CHOOSING THE RIGHT METHOD FOR MISSING VALUES:\n",
    "\n",
    "1. **Drop Nulls** - Use when:\n",
    "   - Dataset is large and missing data is minimal (<5%)\n",
    "   - Missing data appears to be random\n",
    "   - Data quality is more important than quantity\n",
    "\n",
    "2. **Fixed Value Replacement** - Use when:\n",
    "   - Missing values have a meaningful default (e.g., 0 for counts)\n",
    "   - Categorical data with clear \"Unknown\" category\n",
    "   - Simple imputation is acceptable\n",
    "\n",
    "3. **Mean/Median Fill** - Use when:\n",
    "   - Numeric data with normal/skewed distribution respectively\n",
    "   - Missing values are random\n",
    "   - Preserving central tendency is important\n",
    "\n",
    "4. **Mode Fill** - Use when:\n",
    "   - Categorical data\n",
    "   - Preserving most common patterns\n",
    "   - Mixed data types\n",
    "\n",
    "5. **Forward/Backward Fill** - Use when:\n",
    "   - Time series data\n",
    "   - Temporal continuity is important\n",
    "   - Values are expected to persist over time\n",
    "\n",
    "EDGE CASE HANDLING:\n",
    "- Always check for columns with all nulls\n",
    "- Handle mixed data types before imputation\n",
    "- Consider the domain context when choosing methods\n",
    "- Validate results after imputation\n",
    "\n",
    "PERFORMANCE CONSIDERATIONS:\n",
    "- Mode calculation is typically slowest\n",
    "- Forward/backward fill are fastest for time series\n",
    "- Memory usage varies by method complexity\n",
    "\"\"\"\n",
    "\n",
    "print(recommendations)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 9: SAVE RESULTS TO FILES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('missing_values_comparison.csv', index=False)\n",
    "print(\"Comparison results saved to 'missing_values_comparison.csv'\")\n",
    "\n",
    "# Save example of each method\n",
    "for method_name, result in results.items():\n",
    "    if method_name != 'Original':\n",
    "        filename = f\"result_{method_name.lower().replace(' ', '_').replace('(', '').replace(')', '')}.csv\"\n",
    "        result['dataframe'].to_csv(filename, index=False)\n",
    "        print(f\"{method_name} result saved to '{filename}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"All missing value handling methods have been demonstrated and compared.\")\n",
    "print(\"Check the generated CSV files for detailed results.\")\n",
    "print(\"Consider the recommendations above when choosing a method for your specific use case\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
