{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cacf2e6c-ab4f-4706-adeb-30ceaf6187e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607aa8ae-250e-44fa-9844-7f05a0f99187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determines target column by the ratio of unique values in the column\n",
    "A binary column is more likely to be a target column\n",
    "\"\"\"\n",
    "\n",
    "def cardinality_heuristic(df):\n",
    "    scores = {}\n",
    "    n_rows = len(df)\n",
    "    for col in df.columns:\n",
    "        unique_count = df[col].nunique()\n",
    "            \n",
    "        if n_rows == 0:\n",
    "            cardinality_ratio = 0\n",
    "        else:\n",
    "            cardinality_ratio = unique_count / n_rows\n",
    "            \n",
    "        if unique_count == 2:  # Binary classification\n",
    "            scores[col] = 0.8\n",
    "        elif 2 < unique_count <= 10:  # Multi-class classification\n",
    "            scores[col] = 0.7\n",
    "        elif 10 < unique_count <= 50:  # Could be regression \n",
    "            scores[col] = 0.4\n",
    "        elif cardinality_ratio > 0.9:  # Likely unique identifiers\n",
    "            scores[col] = 0.1\n",
    "        else:  # Moderate cardinality\n",
    "            scores[col] = 0.5\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c552321-839d-4f08-91a1-d790c9b9e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of keywords that are very likely to belong to a target column\n",
    "target_names = ['outcome', 'result', 'prediction', 'predict',\n",
    "            'response', 'dependent', 'y', 'price', 'amount', 'value', 'score',\n",
    "            'rating', 'category', 'type', 'status', 'diagnosis', 'churn',\n",
    "            'fraud', 'risk', 'success', 'failure', 'survived', 'approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927a3e04-8102-4292-a228-c27c5728f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of keywords that are very likely to belong to a feature column\n",
    "feature_names = ['id', 'index', 'key', 'name', 'description', 'comment', 'note',\n",
    "            'created', 'updated', 'timestamp', 'date', 'time', 'uuid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04b7a38-a255-406c-945e-608cec2c3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_name_heuristic(df):\n",
    "    scores = {}\n",
    "    for col in df.columns:\n",
    "        score = 0\n",
    "        col_lower = col.lower()\n",
    "        for t_name in target_names:\n",
    "            if t_name in col_lower:\n",
    "                score += 0.8 #High score if name is a likely target column name\n",
    "        if col_lower in ['target', 'label', 'class']:\n",
    "            score += 1 #These are almost certain to be target column names\n",
    "        for f_name in feature_names:\n",
    "            if f_name in col_lower:\n",
    "                score -= 0.5 #Low score if name is a likely feature column name\n",
    "        score = max(0, min(score, 1))\n",
    "        scores[col] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e57fbd2c-aa88-442a-b045-8fe7cead662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target column is expected to have a lower number of null values\n",
    "def null_value_heuristic(df):\n",
    "    scores = {}\n",
    "    if df.isnull().sum().sum() == 0:\n",
    "        for col in df.columns:\n",
    "            scores[col] = 0.5\n",
    "        return scores\n",
    "    for col in df.columns:\n",
    "        null_ratio = df[col].isnull().sum()/len(df)\n",
    "        if null_ratio == 0:\n",
    "            scores[col] = 1\n",
    "        elif null_ratio <= 0.05:\n",
    "            scores[col] = 0.8\n",
    "        elif null_ratio <= 0.1:\n",
    "            scores[col] = 0.6\n",
    "        elif null_ratio <= 0.3:\n",
    "            scores[col] = 0.4\n",
    "        else:\n",
    "            scores[col] = 0.2\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af5831bf-910a-4140-8b06-46705555180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The target column is usually moderately correlated to the feature columns\n",
    "A column with a very low correlation with other columns would not be a suitable target column and is therefore awarded a lower score\n",
    "A column with a very high correlation is likely to be a redundant column that can be explained using the other columns in the dataset \n",
    "\"\"\"\n",
    "def correlation_heuristic(df):\n",
    "    scores = {}\n",
    "    numeric_df = df.select_dtypes(include = 'number')\n",
    "    if len(numeric_df.columns)<2:\n",
    "        return {col: 0.5 for col in df.columns}\n",
    "        \n",
    "    corr_matrix = numeric_df.corr().abs()\n",
    "    for col in df.columns:\n",
    "        if col in numeric_df.columns:\n",
    "            col_corrs = corr_matrix[col].drop(col).dropna()\n",
    "            if len(col_corrs) == 0:\n",
    "                scores[col] = 0.5\n",
    "                continue\n",
    "\n",
    "            max_corr = col_corrs.max()\n",
    "            mean_corr = col_corrs.mean()\n",
    "\n",
    "            if 0.3 <= max_corr <= 0.7 and 0.1 <= mean_corr <= 0.4:\n",
    "                    scores[col] = 0.7\n",
    "            elif max_corr > 0.95:  \n",
    "                    scores[col] = 0.2\n",
    "            elif max_corr < 0.1:\n",
    "                    scores[col] = 0.3\n",
    "            else:\n",
    "                    scores[col] = 0.5\n",
    "        else:\n",
    "                scores[col] = 0.5\n",
    "                \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb0e8f2-7611-4189-a8f4-b7745cb6bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the scores from the four heuristics are combined to generate the final prediction\n",
    "def detect_target_variable(df, weights=None):\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            'cardinality': 0.25,\n",
    "            'name': 0.3,\n",
    "            'null': 0.15,\n",
    "            'correlation': 0.2\n",
    "        }\n",
    "    cardinality_scores = cardinality_heuristic(df)\n",
    "    name_scores = column_name_heuristic(df)\n",
    "    null_scores = null_value_heuristic(df)\n",
    "    correlation_scores = correlation_heuristic(df)\n",
    "    \n",
    "    final_scores = {}\n",
    "    detailed_scores = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        individual_scores = {\n",
    "            'cardinality': cardinality_scores.get(col, 0),\n",
    "            'name': name_scores.get(col, 0),\n",
    "            'null': null_scores.get(col, 0),\n",
    "            'correlation': correlation_scores.get(col, 0)\n",
    "        }\n",
    "        \n",
    "        final_score = sum(individual_scores[metric] * weights[metric] \n",
    "                         for metric in weights.keys())\n",
    "        \n",
    "        final_scores[col] = final_score\n",
    "        detailed_scores[col] = individual_scores\n",
    "    \n",
    "    ranked_columns = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if len(ranked_columns) >= 2:\n",
    "        confidence = ranked_columns[0][1] - ranked_columns[1][1]\n",
    "    else:\n",
    "        confidence = ranked_columns[0][1] if ranked_columns else 0\n",
    "    \n",
    "    return {\n",
    "        'predicted_target': ranked_columns[0][0] if ranked_columns else None,\n",
    "        'confidence': confidence,\n",
    "        'all_scores': final_scores,\n",
    "        'detailed_scores': detailed_scores,\n",
    "        'ranking': ranked_columns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5da088-ab17-4fad-87d5-0b292ec08ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df_titanic = sns.load_dataset('titanic')\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "df_iris = iris.frame.rename(columns={\"target\": \"species_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6dba10-d51d-4645-9497-f620ce4f3a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Titanic\n",
      "Shape: (891, 15)\n",
      "Columns: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "Predicted Target: survived\n",
      "Confidence Score: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "Dataset: Iris\n",
      "Shape: (150, 5)\n",
      "Columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'species_type']\n",
      "Predicted Target: species_type\n",
      "Confidence Score: 0.275\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Titanic\": df_titanic,\n",
    "    \"Iris\": df_iris\n",
    "}\n",
    "df_iris.rename(columns={\"target\": \"species_type\"}, inplace=True)\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "    results = detect_target_variable(df)\n",
    "    \n",
    "    print(f\"Predicted Target: {results['predicted_target']}\")\n",
    "    print(f\"Confidence Score: {results['confidence']:.3f}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1646961-f75f-4ae4-b9b2-be0e091ab23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
