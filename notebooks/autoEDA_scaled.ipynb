{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KvWeoUflIVme"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from scipy.stats import skew\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = input(\"Enter path to CSV (e.g. notebooks/sample_csv/your_file.csv): \")\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuKR02e9QEKa",
        "outputId": "57fb753c-c976-4a0f-a2de-b77ebc373b76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter path to CSV (e.g. notebooks/sample_csv/your_file.csv): /content/Titanic-Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Detect numeric columns (ignore binary/ID-like columns)\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()"
      ],
      "metadata": {
        "id": "ltMIK-h-QHoY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_cols = []\n",
        "for col in numeric_cols:\n",
        "    unique_vals = df[col].nunique()\n",
        "    if unique_vals > 2 and df[col].isnull().mean() < 0.5:\n",
        "        filtered_cols.append(col)"
      ],
      "metadata": {
        "id": "L5M4igbKQPyR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Initializing final DataFrame\n",
        "scaler_report = {}\n",
        "scaled_df = pd.DataFrame(index=df.index)\n",
        "\n",
        "# 4. Auto-scaling logic\n",
        "for col in filtered_cols:\n",
        "    col_data = df[col]\n",
        "    notna_mask = col_data.notna()\n",
        "\n",
        "    scalers = {\n",
        "        'StandardScaler': StandardScaler(),\n",
        "        'MinMaxScaler': MinMaxScaler(),\n",
        "        'RobustScaler': RobustScaler()\n",
        "    }\n",
        "\n",
        "    best_scaler = None\n",
        "    best_skewness = float('inf')\n",
        "    best_scaled_data = None\n",
        "\n",
        "    for name, scaler in scalers.items():\n",
        "        try:\n",
        "            scaled = scaler.fit_transform(col_data[notna_mask].values.reshape(-1, 1))\n",
        "            skewness = abs(skew(scaled.flatten()))\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping scaler {name} on column {col} due to error: {e}\")\n",
        "            continue\n",
        "\n",
        "        if skewness < best_skewness:\n",
        "            best_skewness = skewness\n",
        "            best_scaler = name\n",
        "            best_scaled_data = scaled.flatten()\n",
        "\n",
        "    # Reconstructing full col\n",
        "    full_scaled_col = pd.Series(np.nan, index=col_data.index)\n",
        "    full_scaled_col[notna_mask] = best_scaled_data\n",
        "\n",
        "    # Storing results\n",
        "    scaled_df[col] = full_scaled_col\n",
        "    scaler_report[col] = best_scaler"
      ],
      "metadata": {
        "id": "4DTAkLZvQY_s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Saving output to CSV\n",
        "scaled_df.to_csv(\"autoEDA_scaled_output.csv\", index=False)\n",
        "print(\"\\nâœ… Scaled Data Saved to: autoEDA_scaled_output.csv\")\n",
        "\n",
        "# 6. Report which scaler was used\n",
        "print(\"\\nðŸ“‹ Scaler Report (column : best scaler):\")\n",
        "print(scaler_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "146a2cXVQgJS",
        "outputId": "0129eb8f-324b-49ef-878a-20bb86ec7e32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Scaled Data Saved to: autoEDA_scaled_output.csv\n",
            "\n",
            "ðŸ“‹ Scaler Report (column : best scaler):\n",
            "{'PassengerId': 'RobustScaler', 'Pclass': 'MinMaxScaler', 'Age': 'StandardScaler', 'SibSp': 'StandardScaler', 'Parch': 'RobustScaler', 'Fare': 'StandardScaler'}\n"
          ]
        }
      ]
    }
  ]
}